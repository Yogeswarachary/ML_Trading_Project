{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6d9b124-e1bf-4fef-8fab-96118f0cee0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Models Ridge + XGBoost + LightGBM for Alpha Prediction\n"
     ]
    }
   ],
   "source": [
    "# Imports Required Modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV  # ← Added GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Linear Models Ridge + XGBoost + LightGBM for Alpha Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "572bb7b0-0e46-4327-b979-f25d2a4684cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading 19 alpha factors...\n",
      "Dataset: (2729, 19) features x 2729 observations\n",
      "Target Next-day SPY return mean: 0.0005\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "print(\"1. Loading 19 alpha factors...\")\n",
    "data = pd.read_csv('alpha_factors.csv', index_col=0, parse_dates=True)\n",
    "X = data.drop(columns='spy_return')  # Features\n",
    "y = data['spy_return']               # Target next-day return\n",
    "print(f\"Dataset: {X.shape} features x {len(y)} observations\")\n",
    "print(f\"Target Next-day SPY return mean: {y.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4216a6e-5d92-4c52-ade5-ec53f8e2a49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step2: Time-Series CV setup....\n",
      "Fold 1: Ridge R²=0.118, XGB R²=0.411\n",
      "Fold 2: Ridge R²=-0.045, XGB R²=0.302\n",
      "Fold 3: Ridge R²=0.129, XGB R²=0.479\n",
      "Fold 4: Ridge R²=0.402, XGB R²=0.440\n",
      "Fold 5: Ridge R²=0.332, XGB R²=0.521\n",
      "\n",
      "MEAN R²: Ridge=0.187, XGBoost=0.431\n"
     ]
    }
   ],
   "source": [
    "# Time-Series Cross-Validation for Easy retrival of trading data based on Date\n",
    "print(\"\\nStep2: Time-Series CV setup....\")\n",
    "\n",
    "# This will do 5 folds. Fold1: Train on 2015 - 2018 data, test on 2019 data, similarly for all \n",
    "tscv = TimeSeriesSplit(n_splits = 5)\n",
    "ridge_scores, xgb_scores = [], []\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X.fillna(0)) # Fill NaN for ML\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(tscv.split(X_scaled)):\n",
    "    X_tr, X_te = X_scaled[train_idx], X_scaled[test_idx]\n",
    "    y_tr, y_te = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    # Ridge Regression\n",
    "    ridge = Ridge(alpha = 1.0)\n",
    "    ridge.fit(X_tr, y_tr)\n",
    "    ridge_scores.append(ridge.score(X_te, y_te))\n",
    "\n",
    "    # XGBoost\n",
    "    xgb1 = xgb.XGBRegressor(\n",
    "        n_estimators = 100, \n",
    "        max_depth = 4,\n",
    "        learning_rate = 0.05, \n",
    "        random_state = 42,\n",
    "        objective = 'reg:squarederror'\n",
    "    )\n",
    "    xgb1.fit(X_tr, y_tr)\n",
    "    xgb_scores.append(xgb1.score(X_te, y_te))\n",
    "\n",
    "    print(f\"Fold {i+1}: Ridge R²={ridge.score(X_te, y_te):.3f}, XGB R²={xgb1.score(X_te, y_te):.3f}\")\n",
    "\n",
    "print(f\"\\nMEAN R²: Ridge={np.mean(ridge_scores):.3f}, XGBoost={np.mean(xgb_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a6804f7-b028-486e-b3d8-be06c3eb75e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step3: Hyperparameter Turning..........\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "\n",
      "Best param: {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 100, 'reg_lambda': 1.0, 'subsample': 0.8}\n",
      "\n",
      "Best CV R-Square: 0.397\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Turning for XGBoost\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "print(\"\\nStep3: Hyperparameter Turning..........\")\n",
    "\n",
    "# Conservative Params for Financial Data - To avoid overfitting\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [3, 4],\n",
    "    'learning_rate': [0.01, 0.05],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'reg_lambda': [1.0, 2.0] # L2 for Regularization\n",
    "}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits = 3) # Fewer folds for Speed\n",
    "xgb_grid = GridSearchCV(\n",
    "    xgb.XGBRegressor(random_state = 42, objective = 'reg:squarederror'),\n",
    "    xgb_param_grid, cv = tscv, scoring = 'r2', n_jobs = -1, verbose = 1\n",
    ")\n",
    "\n",
    "# Apply standard scaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled_tune = scaler.fit_transform(X.fillna(0))\n",
    "\n",
    "# Fit on First 80% for Tuning\n",
    "split_tune = int(0.8 * len(X_scaled_tune))\n",
    "xgb_grid.fit(X_scaled_tune[:split_tune], y.iloc[:split_tune])\n",
    "\n",
    "print(f\"\\nBest param: {xgb_grid.best_params_}\")\n",
    "print(f\"\\nBest CV R-Square: {xgb_grid.best_score_:.3f}\")\n",
    "\n",
    "# use best parameters for final model\n",
    "best_xgb_params = xgb_grid.best_params_\n",
    "best_xgb_params.update({'random_state': 42, 'objective':'reg:squarederror'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dec0a7bc-ef78-4842-881b-92d33b30cfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step4: Train/Test Split...\n",
      "Train: 2183 days, Test: 546 days\n",
      "OOS Test R²: 0.535\n"
     ]
    }
   ],
   "source": [
    "# Train/Test Split + Model\n",
    "print(\"\\nStep4: Train/Test Split...\")\n",
    "split_idx = int(0.8 * len(X))\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X.fillna(0))\n",
    "X_train, X_test = X_scaled[:split_idx], X_scaled[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "print(f\"Train: {len(X_train)} days, Test: {len(X_test)} days\")\n",
    "\n",
    "# Use best params\n",
    "final_xgb = xgb.XGBRegressor(**best_xgb_params)\n",
    "final_xgb.fit(X_train, y_train)\n",
    "\n",
    "data['predictedreturn'] = pd.Series(final_xgb.predict(X_scaled), index=X.index)\n",
    "test_r2 = final_xgb.score(X_test, y_test)\n",
    "print(f\"OOS Test R²: {test_r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e67b044-3d4d-4cc0-a50f-f5c646f18aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step6: Long Only Strategy...\n",
      "LONG-ONLY Sharpe: 0.418\n",
      "Long signals: 1056\n",
      "Avg weight: 0.31\n",
      "Turnover: 0.50\n"
     ]
    }
   ],
   "source": [
    "# We are now using the Long Only Strategy\n",
    "print(\"\\nStep6: Long Only Strategy...\")\n",
    "\n",
    "pred_std = data['predictedreturn'].std()\n",
    "long_threshold = 0.3 * pred_std  # change back to 5\n",
    "\n",
    "# LONG-ONLY: No shorts, just best long signals\n",
    "data['long_signal'] = (data['predictedreturn'] > long_threshold).astype(int)\n",
    "data['weight'] = data['long_signal'] * 0.8  # 80% position on best signals\n",
    "\n",
    "# Smooth to hold winners longer\n",
    "data['weight'] = data['weight'].ewm(span=5).mean()\n",
    "data['strategy_return'] = data['weight'].shift(1) * data['spy_return']\n",
    "sharpe_ratio = data['strategy_return'].mean() / data['strategy_return'].std() * np.sqrt(252)\n",
    "\n",
    "print(f\"LONG-ONLY Sharpe: {sharpe_ratio:.3f}\")\n",
    "print(f\"Long signals: {(data['long_signal']==1).sum()}\")\n",
    "print(f\"Avg weight: {data['weight'].mean():.2f}\")\n",
    "print(f\"Turnover: {(data['weight'].diff().abs() > 0.1).mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b08a9a9-f6de-456a-9095-5356d1900b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step7: Benchmark Comparision\n",
      "==================================================\n",
      "STRATEGY PERFORMANCE\n",
      "==================================================\n",
      "Strategy (Gross) Sharpe:   0.418\n",
      "Net Sharpe (after costs):  0.327\n",
      "--------------------------------------------------\n",
      "LONG-ONLY 60% SPY Sharpe:  0.701\n",
      "Alpha vs Long-only:        -0.283\n",
      "==================================================\n",
      "Turnover: 10.7% (27 trades/year)\n",
      "Win Rate (trading days): 55.2%\n",
      "Max Drawdown: -16.1%\n"
     ]
    }
   ],
   "source": [
    "# Transaction Costs\n",
    "# LONG-ONLY BENCHMARK + TRANSACTION COSTS\n",
    "print(\"\\nStep7: Benchmark Comparision\")\n",
    "\n",
    "# 1. LONG-ONLY BENCHMARK (60% constant SPY exposure)\n",
    "data['long_only'] = 0.8 * data['spy_return'] # Change back 6\n",
    "long_only_sharpe = data['long_only'].mean() / data['long_only'].std() * np.sqrt(252)\n",
    "long_only_alpha = sharpe_ratio - long_only_sharpe\n",
    "\n",
    "# 2. QUICK TRANSACTION COSTS (simplified)\n",
    "turnover = data['weight'].diff().abs().fillna(0)\n",
    "tc_bps = 2 / 10000  # 2bps round-trip (conservative)\n",
    "data['tc_cost'] = turnover * tc_bps\n",
    "data['net_return'] = data['strategy_return'] - data['tc_cost']\n",
    "net_sharpe = data['net_return'].mean() / data['net_return'].std() * np.sqrt(252)\n",
    "\n",
    "# 3. RESULTS TABLE\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"STRATEGY PERFORMANCE\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Strategy (Gross) Sharpe:   {sharpe_ratio:.3f}\")\n",
    "print(f\"Net Sharpe (after costs):  {net_sharpe:.3f}\")\n",
    "print(f\"{'-'*50}\")\n",
    "print(f\"LONG-ONLY 60% SPY Sharpe:  {long_only_sharpe:.3f}\")\n",
    "print(f\"Alpha vs Long-only:        {long_only_alpha:.3f}\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Turnover: {turnover.mean():.1%} ({turnover.mean()*252:.0f} trades/year)\")\n",
    "\n",
    "# Winrate\n",
    "trading_days = data['weight'].abs() > 0.01\n",
    "win_rate = (data['strategy_return'][trading_days] > 0).mean()\n",
    "print(f\"Win Rate (trading days): {win_rate:.1%}\")\n",
    "\n",
    "# Max Drawdown\n",
    "equity_curve = (1 + data['strategy_return']).cumprod()\n",
    "running_max = equity_curve.expanding().max()\n",
    "drawdown = (equity_curve - running_max) / running_max\n",
    "max_dd = drawdown.min()\n",
    "print(f\"Max Drawdown: {max_dd:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7249fef-9f83-46c6-8ca6-c2a4f98e92dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved daily results to: C:\\Users\\myoge\\Contacts\\Regression Based Project\\runs\\trading_results_2026-01-05.csv\n"
     ]
    }
   ],
   "source": [
    "# Add this as the FINAL cell in Production_v1.0.ipynb\n",
    "import os\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "\n",
    "base_path = r\"C:\\Users\\myoge\\Contacts\\Regression Based Project\"\n",
    "runs_path = os.path.join(base_path, \"runs\")\n",
    "os.makedirs(runs_path, exist_ok=True)\n",
    "\n",
    "run_date = date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Create daily summary WITH Sharpe column (required by app.py)\n",
    "daily_summary = pd.DataFrame({\n",
    "    'Date': [run_date],\n",
    "    'sharpe_gross': [sharpe_ratio],\n",
    "    'sharpe_net': [net_sharpe],\n",
    "    'win_rate': [win_rate],\n",
    "    'max_drawdown': [max_dd],\n",
    "    'long_signals': [(data['long_signal']==1).sum()],\n",
    "    'turnover': [turnover.mean()]\n",
    "})\n",
    "\n",
    "out_path = os.path.join(runs_path, f\"trading_results_{run_date}.csv\")\n",
    "daily_summary.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"✅ Saved daily results to: {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7cfa46-a264-480d-9228-2b3492d795d5",
   "metadata": {},
   "source": [
    "### Final Summary about the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5766437c-a261-43ca-ae5c-dfe1b14e7a4a",
   "metadata": {},
   "source": [
    "#### Phase1: Data & Prediction Power\n",
    "- 19 Alpha Factors → 2729 trading days (2015-2025)\n",
    "> Target: Next-day SPY return (mean +0.0005/day)\n",
    "- Model Performance:\n",
    "> Ridge Regression: R² = 0.187 (Baseline)\n",
    ">\n",
    "> XGBoost (Tuned): R² = 0.431 CV → **0.535 OOS**\n",
    "\n",
    "#### Phase2: Hyper Parameter Optimization\n",
    "- GridSearchCV: 48 fits across 16 parameter combinations\n",
    "- Best XGBoost: n_estimators=100, max_depth=4, lr=0.05\n",
    "- CV R²: 0.397 → OOS Test R²: 0.535\n",
    "\n",
    "#### Phase3: Trading Logic Evolution\n",
    "- Original: Naive signals → Sharpe -0.80 (100% turnover)\n",
    "- v1.0: Long-only + thresholds → Sharpe +0.418 (27 trades/year)\n",
    "- Key Innovation: 0.3× prediction std threshold = SWEET SPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929c9647-1308-4cf1-9a2a-dc9b3e9302da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
